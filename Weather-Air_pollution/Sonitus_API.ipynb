{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "         serial_number               label  \\\n",
      "0             10.1.1.1             Noise 1   \n",
      "1                01749             Noise 2   \n",
      "2                01508             Noise 3   \n",
      "3                10118             Noise 4   \n",
      "4                01548             Noise 5   \n",
      "5                10115             Noise 6   \n",
      "6             10.1.1.7             Noise 7   \n",
      "7                01870             Noise 8   \n",
      "8                01575             Noise 9   \n",
      "9                01737            Noise 10   \n",
      "10           10.1.1.11            Noise 11   \n",
      "11           10.1.1.12            Noise 12   \n",
      "12               01550            Noise 13   \n",
      "13               01534            Noise 14   \n",
      "14               01535            Noise 16   \n",
      "15               01509            Noise 17   \n",
      "16               01529            Noise 18   \n",
      "17               01530      Noise 19 Spare   \n",
      "18               01528            Noise 20   \n",
      "19             DCC-AQ1      National Air 1   \n",
      "20             DCC-AQ2      National Air 2   \n",
      "21             DCC-AQ3      National Air 3   \n",
      "22             DCC-AQ4      National Air 4   \n",
      "23             DCC-AQ5      National Air 5   \n",
      "24             DCC-AQ6      National Air 6   \n",
      "25             DCC-AQ7      National Air 7   \n",
      "26             DCC-AQ8      National Air 8   \n",
      "27             DCC-AQ9      National Air 9   \n",
      "28            DCC-AQ10     National Air 10   \n",
      "29          DM30-00118          DM30-00118   \n",
      "30             TNT1088  Former Local Air 6   \n",
      "31             TNT1138         Local Air 2   \n",
      "32             TNT1296  Former Local Air 1   \n",
      "33             TNO2161         Local Air 4   \n",
      "34             TNO2162         Local Air 7   \n",
      "35            DCC-AQ13     National Air 13   \n",
      "36            DCC-AQ17     National Air 17   \n",
      "37            DCC-AQ22     National Air 22   \n",
      "38            DCC-AQ52     National Air 52   \n",
      "39            DCC-AQ69     National Air 69   \n",
      "40             TNO4435         Local Air 2   \n",
      "41             TNO4438        Local Air 11   \n",
      "42             TNO4488         Local Air 9   \n",
      "43             TNO4390        Local Air 10   \n",
      "44             TNO4324         Local Air 5   \n",
      "45             TNO4323         Local Air 6   \n",
      "46             TNO4325  Former Local Air 2   \n",
      "47             TNO4437         Local Air 1   \n",
      "48  0110-000157-000000        Local Air 13   \n",
      "49  0110-000180-000000        Local Air 14   \n",
      "50  0110-000141-000000         Local Air 8   \n",
      "51          DM30-00530         Local Air 9   \n",
      "52          DM30-00531        Local Air 12   \n",
      "53            DCC-AQ91     National Air 91   \n",
      "\n",
      "                              location    latitude   longitude last_calibrated  \n",
      "0                   Drumcondra Library   53.369864   -6.258966      2018-08-29  \n",
      "1                          Bull Island    53.36866   -6.149316      2023-03-13  \n",
      "2             Ballyfermot Civic Centre   53.343337   -6.362923      2022-02-08  \n",
      "3                             Ballymun   53.390401   -6.264755      2023-03-01  \n",
      "4                      DCC Rowing Club   53.346116   -6.321013      2023-02-21  \n",
      "5                          Walkinstown   53.319492   -6.321945      2023-02-28  \n",
      "6                    Woodstock Gardens   53.323524   -6.247734      2021-01-20  \n",
      "7                           Navan Road   53.370758   -6.325578      2023-08-22  \n",
      "8                               Raheny   53.379996   -6.172829      2023-02-21  \n",
      "9               Ringsend Sports Centre   53.340031  -6.2200231      2023-03-07  \n",
      "10                      Chancery Park    53.346694   -6.272244      2021-01-28  \n",
      "11                   Blessington Basin   53.357153   -6.270895      2021-02-01  \n",
      "12                       Dolphins Barn   53.331059   -6.292452      2023-02-21  \n",
      "13  Woodstock Gardens Temp replacement   53.323204   -6.247469      2022-03-24  \n",
      "14  Blessington Basin Temp replacement   53.357153   -6.270895      2022-03-24  \n",
      "15                         Strand Road  53.3279804  -6.2088104      2023-02-21  \n",
      "16      Chancery Park Temp Replacement   53.346665   -6.272211      2022-03-21  \n",
      "17                           In Office                              2022-03-22  \n",
      "18         Drumcondra Temp Replacement   53.369847   -6.258945      2022-03-21  \n",
      "19                        Civic Centre  53.3442389   -6.271525      0000-00-00  \n",
      "20                              Marino  53.3680667    -6.22785      0000-00-00  \n",
      "21                        Phoenix Park  53.3644417  -6.3489667      0000-00-00  \n",
      "22                             Finglas   53.390281   -6.305769      0000-00-00  \n",
      "23                         Ballyfermot   53.340148    -6.35181      0000-00-00  \n",
      "24                         Davitt Road  53.3362889  -6.3090056      0000-00-00  \n",
      "25                      Blanchardstown  53.3856444   -6.369925      0000-00-00  \n",
      "26                       Dun Laoghaire  53.2857556  -6.1318222      0000-00-00  \n",
      "27                            Old Bawn  53.2805333  -6.3560444      0000-00-00  \n",
      "28                  St Johns Road West   53.345707   -6.295775      0000-00-00  \n",
      "29                    Ballymun Library   53.390398   -6.265060      0000-00-00  \n",
      "30        Formerly Walkinstown Library   53.318902    -6.32176      2019-10-31  \n",
      "31                 Formerly Drumcondra   53.369894   -6.259124      0000-00-00  \n",
      "32           Formerly Ballymun Library   53.390433   -6.265270      2019-10-31  \n",
      "33                   Custom House Quay   53.347863   -6.243785      0000-00-00  \n",
      "34                             Coolock   53.390542   -6.202395      0000-00-00  \n",
      "35                         Dublin Port   53.351671   -6.203778      0000-00-00  \n",
      "36                            Ringsend   53.341938   -6.214116      0000-00-00  \n",
      "37                           Rathmines   53.322029   -6.267154      0000-00-00  \n",
      "38             St. Anne's Park, Raheny   53.372904   -6.179390            None  \n",
      "39                       Pearse Street   53.345053   -6.254344      0000-00-00  \n",
      "40                          Drumcondra     53.3699     -6.2591      0000-00-00  \n",
      "41             Cabra Community College  53.3687022     -6.2943      0000-00-00  \n",
      "42            Sandymount Green, Dublin    53.33192   -6.215766            None  \n",
      "43              TU Dublin - Park House   53.357689   -6.287134      0000-00-00  \n",
      "44                  Lord Edward Street   53.343628   -6.270197      0000-00-00  \n",
      "45                 Walkinstown Library   53.318902    -6.32176      0000-00-00  \n",
      "46                 Formerly Drumcondra   53.369894   -6.259124      0000-00-00  \n",
      "47                    Ballymun Library   53.390433   -6.265270      0000-00-00  \n",
      "48                     Mountjoy Square   53.356816   -6.256876      0000-00-00  \n",
      "49                            Kylemore   53.333691   -6.350796      0000-00-00  \n",
      "50                         Weaver Park   53.337909   -6.281161      0000-00-00  \n",
      "51                    Sandymount Green    53.33192   -6.215766            None  \n",
      "52             Donnybrook Fire Station   53.322562  -6.2370145            None  \n",
      "53                       Amiens Street   53.352372   -6.249015            None  \n"
     ]
    }
   ],
   "source": [
    "# get sensor data from https://data.smartdublin.ie/sonitus-api\n",
    "# map that displays the data : https://dublincityairandnoise.ie/\n",
    "# page : https://data.gov.ie/dataset/sonitus/resource/38a117c9-79b5-4e1c-9080-ed862bbe689d\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://data.smartdublin.ie/sonitus-api/api/monitors'\n",
    "\n",
    "# Set the parameters for the POST request\n",
    "params = {\n",
    "    'username': 'dublincityapi',\n",
    "    'password': 'Xpa5vAQ9ki'\n",
    "}\n",
    "\n",
    "# Set headers\n",
    "headers = {\n",
    "    'accept': '*/*'\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Data fetched successfully!\")\n",
    "    # Get JSON response data\n",
    "    monitors_data = response.json()\n",
    "    \n",
    "    # Creating a list to store each monitor's data\n",
    "    monitors_list = []\n",
    "    \n",
    "    # Assume each entry in the JSON data is a monitor\n",
    "    for monitor in monitors_data:\n",
    "        # Parse each monitor's data into a structured dictionary\n",
    "        monitor_data = {\n",
    "            'serial_number': monitor['serial_number'],  # Assuming 'id' is part of the monitor data\n",
    "            'label': monitor['label'],  # Assuming 'location' details\n",
    "            'location': monitor['location'],  # Assuming 'status' indicates if the monitor is active\n",
    "            'latitude': monitor['latitude'],  # Assuming latitude info\n",
    "            'longitude': monitor['longitude'],  # Assuming longitude info\n",
    "            'last_calibrated': monitor['last_calibrated'],\n",
    "            # Add additional fields as per your API response structure\n",
    "            #'Current Rating' : monitor['current_rating']\n",
    "        }\n",
    "        monitors_list.append(monitor_data)\n",
    "    \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    monitors_df = pd.DataFrame(monitors_list)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(monitors_df)\n",
    "else:\n",
    "    print(\"Failed to fetch data:\")\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response Body:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this code selects only the air data monitors and fetches their serial numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DCC-AQ1',\n",
       " 'DCC-AQ2',\n",
       " 'DCC-AQ3',\n",
       " 'DCC-AQ4',\n",
       " 'DCC-AQ5',\n",
       " 'DCC-AQ6',\n",
       " 'DCC-AQ7',\n",
       " 'DCC-AQ8',\n",
       " 'DCC-AQ9',\n",
       " 'DCC-AQ10',\n",
       " 'TNT1088',\n",
       " 'TNT1138',\n",
       " 'TNT1296',\n",
       " 'TNO2161',\n",
       " 'TNO2162',\n",
       " 'DCC-AQ13',\n",
       " 'DCC-AQ17',\n",
       " 'DCC-AQ22',\n",
       " 'DCC-AQ52',\n",
       " 'DCC-AQ69',\n",
       " 'TNO4435',\n",
       " 'TNO4438',\n",
       " 'TNO4488',\n",
       " 'TNO4390',\n",
       " 'TNO4324',\n",
       " 'TNO4323',\n",
       " 'TNO4325',\n",
       " 'TNO4437',\n",
       " '0110-000157-000000',\n",
       " '0110-000180-000000',\n",
       " '0110-000141-000000',\n",
       " 'DM30-00530',\n",
       " 'DM30-00531',\n",
       " 'DCC-AQ91']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the df created above and only save the rows where air appears. \n",
    "# This is because we are only interested in the air quality sensors.\n",
    "\n",
    "# Filtering to create a new DataFrame where 'description' contains \"Air\"\n",
    "monitors_air = monitors_df[monitors_df['label'].str.contains(\"Air\")]\n",
    "\n",
    "# Print the new DataFrame\n",
    "#print(monitors_air)\n",
    "# These are the sensors we care about\n",
    "\n",
    "# then we loop over the serial number to get the hourly averages. \n",
    "serial_numbers = monitors_air['serial_number'].tolist() # get a list of serial numbers\n",
    "serial_numbers\n",
    "#len(serial_numbers) # 34 sensors for air quality\n",
    "# use this list for the next code \n",
    "\n",
    "\n",
    "# limitation, no last calibration data for the pollution data so we \n",
    "# have to acknowledge that the data might have been calibrated last before our period of analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code generates a list containing Unix timestamps for each day from May 1, 2021, to August 31, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1619820000, 1619906400, 1619992800, 1620079200, 1620165600, 1620252000, 1620338400, 1620424800, 1620511200, 1620597600, 1620684000, 1620770400, 1620856800, 1620943200, 1621029600, 1621116000, 1621202400, 1621288800, 1621375200, 1621461600, 1621548000, 1621634400, 1621720800, 1621807200, 1621893600, 1621980000, 1622066400, 1622152800, 1622239200, 1622325600, 1622412000, 1622498400, 1622584800, 1622671200, 1622757600, 1622844000, 1622930400, 1623016800, 1623103200, 1623189600, 1623276000, 1623362400, 1623448800, 1623535200, 1623621600, 1623708000, 1623794400, 1623880800, 1623967200, 1624053600, 1624140000, 1624226400, 1624312800, 1624399200, 1624485600, 1624572000, 1624658400, 1624744800, 1624831200, 1624917600, 1625004000, 1625090400, 1625176800, 1625263200, 1625349600, 1625436000, 1625522400, 1625608800, 1625695200, 1625781600, 1625868000, 1625954400, 1626040800, 1626127200, 1626213600, 1626300000, 1626386400, 1626472800, 1626559200, 1626645600, 1626732000, 1626818400, 1626904800, 1626991200, 1627077600, 1627164000, 1627250400, 1627336800, 1627423200, 1627509600, 1627596000, 1627682400, 1627768800, 1627855200, 1627941600, 1628028000, 1628114400, 1628200800, 1628287200, 1628373600, 1628460000, 1628546400, 1628632800, 1628719200, 1628805600, 1628892000, 1628978400, 1629064800, 1629151200, 1629237600, 1629324000, 1629410400, 1629496800, 1629583200, 1629669600, 1629756000, 1629842400, 1629928800, 1630015200, 1630101600, 1630188000, 1630274400, 1630360800, 1630447200, 1630533600, 1630620000, 1630706400, 1630792800, 1630879200, 1630965600, 1631052000, 1631138400, 1631224800, 1631311200, 1631397600, 1631484000, 1631570400, 1631656800, 1631743200, 1631829600, 1631916000, 1632002400, 1632088800, 1632175200, 1632261600, 1632348000, 1632434400, 1632520800, 1632607200, 1632693600, 1632780000, 1632866400, 1632952800, 1633039200, 1633125600, 1633212000, 1633298400, 1633384800, 1633471200, 1633557600, 1633644000, 1633730400, 1633816800, 1633903200, 1633989600, 1634076000, 1634162400, 1634248800, 1634335200, 1634421600, 1634508000, 1634594400, 1634680800, 1634767200, 1634853600, 1634940000, 1635026400, 1635112800, 1635199200, 1635285600, 1635372000, 1635458400, 1635544800, 1635631200, 1635721200, 1635807600, 1635894000, 1635980400, 1636066800, 1636153200, 1636239600, 1636326000, 1636412400, 1636498800, 1636585200, 1636671600, 1636758000, 1636844400, 1636930800, 1637017200, 1637103600, 1637190000, 1637276400, 1637362800, 1637449200, 1637535600, 1637622000, 1637708400, 1637794800, 1637881200, 1637967600, 1638054000, 1638140400, 1638226800, 1638313200, 1638399600, 1638486000, 1638572400, 1638658800, 1638745200, 1638831600, 1638918000, 1639004400, 1639090800, 1639177200, 1639263600, 1639350000, 1639436400, 1639522800, 1639609200, 1639695600, 1639782000, 1639868400, 1639954800, 1640041200, 1640127600, 1640214000, 1640300400, 1640386800, 1640473200, 1640559600, 1640646000, 1640732400, 1640818800, 1640905200, 1640991600, 1641078000, 1641164400, 1641250800, 1641337200, 1641423600, 1641510000, 1641596400, 1641682800, 1641769200, 1641855600, 1641942000, 1642028400, 1642114800, 1642201200, 1642287600, 1642374000, 1642460400, 1642546800, 1642633200, 1642719600, 1642806000, 1642892400, 1642978800, 1643065200, 1643151600, 1643238000, 1643324400, 1643410800, 1643497200, 1643583600, 1643670000, 1643756400, 1643842800, 1643929200, 1644015600, 1644102000, 1644188400, 1644274800, 1644361200, 1644447600, 1644534000, 1644620400, 1644706800, 1644793200, 1644879600, 1644966000, 1645052400, 1645138800, 1645225200, 1645311600, 1645398000, 1645484400, 1645570800, 1645657200, 1645743600, 1645830000, 1645916400, 1646002800, 1646089200, 1646175600, 1646262000, 1646348400, 1646434800, 1646521200, 1646607600, 1646694000, 1646780400, 1646866800, 1646953200, 1647039600, 1647126000, 1647212400, 1647298800, 1647385200, 1647471600, 1647558000, 1647644400, 1647730800, 1647817200, 1647903600, 1647990000, 1648076400, 1648162800, 1648249200, 1648335600, 1648418400, 1648504800, 1648591200, 1648677600, 1648764000, 1648850400, 1648936800, 1649023200, 1649109600, 1649196000, 1649282400, 1649368800, 1649455200, 1649541600, 1649628000, 1649714400, 1649800800, 1649887200, 1649973600, 1650060000, 1650146400, 1650232800, 1650319200, 1650405600, 1650492000, 1650578400, 1650664800, 1650751200, 1650837600, 1650924000, 1651010400, 1651096800, 1651183200, 1651269600, 1651356000, 1651442400, 1651528800, 1651615200, 1651701600, 1651788000, 1651874400, 1651960800, 1652047200, 1652133600, 1652220000, 1652306400, 1652392800, 1652479200, 1652565600, 1652652000, 1652738400, 1652824800, 1652911200, 1652997600, 1653084000, 1653170400, 1653256800, 1653343200, 1653429600, 1653516000, 1653602400, 1653688800, 1653775200, 1653861600, 1653948000, 1654034400, 1654120800, 1654207200, 1654293600, 1654380000, 1654466400, 1654552800, 1654639200, 1654725600, 1654812000, 1654898400, 1654984800, 1655071200, 1655157600, 1655244000, 1655330400, 1655416800, 1655503200, 1655589600, 1655676000, 1655762400, 1655848800, 1655935200, 1656021600, 1656108000, 1656194400, 1656280800, 1656367200, 1656453600, 1656540000, 1656626400, 1656712800, 1656799200, 1656885600, 1656972000, 1657058400, 1657144800, 1657231200, 1657317600, 1657404000, 1657490400, 1657576800, 1657663200, 1657749600, 1657836000, 1657922400, 1658008800, 1658095200, 1658181600, 1658268000, 1658354400, 1658440800, 1658527200, 1658613600, 1658700000, 1658786400, 1658872800, 1658959200, 1659045600, 1659132000, 1659218400, 1659304800, 1659391200, 1659477600, 1659564000, 1659650400, 1659736800, 1659823200, 1659909600, 1659996000, 1660082400, 1660168800, 1660255200, 1660341600, 1660428000, 1660514400, 1660600800, 1660687200, 1660773600, 1660860000, 1660946400, 1661032800, 1661119200, 1661205600, 1661292000, 1661378400, 1661464800, 1661551200, 1661637600, 1661724000, 1661810400, 1661896800]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1622239200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to convert date to Unix timestamp\n",
    "def unix_timestamp(date):\n",
    "    return int(date.timestamp())\n",
    "\n",
    "# Generate dates from May 1, 2021, to August 31, 2022\n",
    "start_date = datetime(2021, 5, 1)\n",
    "end_date = datetime(2022, 8, 31)\n",
    "\n",
    "dates = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Convert dates to Unix timestamps\n",
    "unix_timestamps = [unix_timestamp(date) for date in dates]\n",
    "\n",
    "# Store Unix timestamps in a list\n",
    "timestamp_list = unix_timestamps\n",
    "\n",
    "# Print the list\n",
    "print(timestamp_list)\n",
    "\n",
    "len(timestamp_list) # 488 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622239200\n"
     ]
    }
   ],
   "source": [
    "# here you get timestampt for singular days \n",
    "from datetime import datetime\n",
    "\n",
    "# Create a datetime object for May 30, 2021\n",
    "date = datetime(2021, 5, 29)\n",
    "\n",
    "# Convert the datetime object to a Unix timestamp\n",
    "unix_timestamp = int(date.timestamp())\n",
    "\n",
    "# Print the Unix timestamp\n",
    "print(unix_timestamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My chatgpt prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have a list of serial numbers and we have a list of unix_timestamps for every day from 2021-05-01 to 2022-08-31. The api allows me to fetch 29 days at the time. Need a code that updates the params so that for every monitor in the list, the data for the period from 2021-05-01 to 2022-08-31 is scraped 29 days at the time. the last scraping batch does not have to be 29 days and can be the remaining days to be scraped.  there must be a column with the serial_number corresponding to the row scraped. \n",
    "\n",
    "I would like all the air pollution data for every monitor to be saved in different csvs in different folders. In the end, I want to have as many folders as the number of air monitors (34 i believe). Then, would like all these monitor data to be merged in a big dataset called \"Air_pollution_Sonitus\". This is the code to start from: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully!\n",
      "                datetime   pm1   pm10  pm2_5    tsp\n",
      "0    2021-05-01 00:00:00  2.88  10.87   5.62  17.40\n",
      "1    2021-05-01 01:00:00  2.27   7.55   4.25  10.92\n",
      "2    2021-05-01 02:00:00  2.44   8.32   4.55  12.33\n",
      "3    2021-05-01 03:00:00  2.73   8.85   4.99  12.67\n",
      "4    2021-05-01 04:00:00  2.44   7.83   4.43  10.82\n",
      "..                   ...   ...    ...    ...    ...\n",
      "666  2021-05-28 18:00:00  3.63  11.47   7.34  14.95\n",
      "667  2021-05-28 19:00:00  3.57  10.90   7.09  14.02\n",
      "668  2021-05-28 20:00:00  2.87   8.90   5.76  11.60\n",
      "669  2021-05-28 21:00:00  2.52   7.73   4.91  10.15\n",
      "670  2021-05-28 22:00:00  2.53   7.77   4.79  10.32\n",
      "\n",
      "[671 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://data.smartdublin.ie/sonitus-api/api/hourly-averages'\n",
    "\n",
    "# Set the parameters for the POST request\n",
    "params = {\n",
    "    'username': 'dublincityapi',\n",
    "    'password': 'Xpa5vAQ9ki',\n",
    "    'monitor': 'TNO4435',  # air monitor serial numbers \n",
    "    'start': '1619827200',  # 2021-05-01 00:00:00\n",
    "    'end': '1622239200'     # 2021-05-29 00:00:00\n",
    "}\n",
    "\n",
    "# Set headers\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Data fetched successfully!\")\n",
    "    # Get JSON response data\n",
    "    data = response.json()\n",
    "    \n",
    "    # Creating a list to store each record's data\n",
    "    records_list = []\n",
    "    for record in data:\n",
    "        # Extracting details for each record\n",
    "        record_data = {\n",
    "            'datetime': record['datetime'],\n",
    "            'pm1': record.get('pm1', 0),        # Defaulting to 0 if any key is missing\n",
    "            'pm10': record.get('pm10', 0),\n",
    "            'pm2_5': record.get('pm2_5', 0),\n",
    "            'tsp': record.get('tsp', 0)\n",
    "        }\n",
    "        records_list.append(record_data)\n",
    "    \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    df = pd.DataFrame(records_list)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Failed to fetch data:\")\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response Body:\", response.text)\n",
    "\n",
    "\n",
    "\n",
    "    # things missing in this code: \n",
    "    # must add the monitor id \n",
    "    # then put the longitude and latitude \n",
    "    # must figure out a way that has the code scrap 29 days at the time. \n",
    "           # figure out if date format can be produced through code otherwise ask chat to provide a list for the time span \n",
    "\n",
    "\n",
    "# question,\n",
    "# relevant even if the longitudes and latitudes are not the same with the intersection ones? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Add serial number to each record\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# test \n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://data.smartdublin.ie/sonitus-api/api/hourly-averages'\n",
    "\n",
    "# Set headers\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Define your credentials\n",
    "username = 'dublincityapi'\n",
    "password = 'Xpa5vAQ9ki'\n",
    "\n",
    "# Convert date string to unix timestamp\n",
    "def date_to_unix(date_str):\n",
    "    return int(datetime.strptime(date_str, '%Y-%m-%d').timestamp())\n",
    "\n",
    "# Generate date ranges for the period, 29 days at a time\n",
    "def generate_date_ranges(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        yield current_date, min(end_date, current_date + timedelta(days=15))\n",
    "        current_date += timedelta(days=30)\n",
    "\n",
    "# Monitor serial numbers and date range\n",
    "serial_numbers = serial_numbers  \n",
    "start_date = datetime(2021, 5, 1)\n",
    "end_date = datetime(2022, 8, 31)\n",
    "\n",
    "# Directory for all CSVs\n",
    "base_directory = \"Air_Pollution_Data\"\n",
    "os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "# Data container for all monitors\n",
    "all_data = []\n",
    "\n",
    "# Loop through each serial number and fetch data\n",
    "for serial in serial_numbers:\n",
    "    # Create directory for each monitor\n",
    "    monitor_directory = os.path.join(base_directory, serial)\n",
    "    os.makedirs(monitor_directory, exist_ok=True)\n",
    "    \n",
    "    monitor_data_list = []\n",
    "    \n",
    "    # Generate data for each time period\n",
    "    for start, end in generate_date_ranges(start_date, end_date):\n",
    "        # Set parameters for POST request\n",
    "        params = {\n",
    "            'username': username,\n",
    "            'password': password,\n",
    "            'monitor': serial,\n",
    "            'start': date_to_unix(start.strftime('%Y-%m-%d')),\n",
    "            'end': date_to_unix(end.strftime('%Y-%m-%d'))\n",
    "        }\n",
    "        \n",
    "        # Send the POST request\n",
    "        response = requests.post(url, headers=headers, params=params)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Add serial number to each record\n",
    "            for record in data:\n",
    "                record['serial_number'] = serial\n",
    "                monitor_data_list.append(record)\n",
    "                \n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {serial} from {start} to {end}\")\n",
    "            print(\"Status Code:\", response.status_code)\n",
    "            print(\"Response Body:\", response.text)\n",
    "        \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    monitor_df = pd.DataFrame(monitor_data_list)\n",
    "    \n",
    "    # Save to CSV in its respective directory\n",
    "    csv_path = os.path.join(monitor_directory, f\"{serial}.csv\")\n",
    "    monitor_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Collect data for final aggregation\n",
    "    all_data.append(monitor_df)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV\n",
    "combined_csv_path = os.path.join(base_directory, \"Air_pollution_Sonitus.csv\")\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "print(\"All data has been fetched and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n",
      "\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n",
      "\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n",
      "\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n",
      "\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n",
      "\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n",
      "\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n",
      "\u001b[0;32m    335\u001b[0m \n",
      "\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n",
      "\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[37], line 66\u001b[0m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n",
      "\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;32m---> 66\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Add serial number to each record\u001b[39;00m\n",
      "\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n",
      "\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# test \n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://data.smartdublin.ie/sonitus-api/api/hourly-averages'\n",
    "\n",
    "# Set headers\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Define your credentials\n",
    "username = 'dublincityapi'\n",
    "password = 'Xpa5vAQ9ki'\n",
    "\n",
    "# Convert date string to unix timestamp\n",
    "def date_to_unix(date_str):\n",
    "    return int(datetime.strptime(date_str, '%Y-%m-%d').timestamp())\n",
    "\n",
    "# Generate date ranges for the period, 29 days at a time\n",
    "def generate_date_ranges(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        yield current_date, min(end_date, current_date + timedelta(days=15))\n",
    "        current_date += timedelta(days=30)\n",
    "\n",
    "# Monitor serial numbers and date range\n",
    "serial_numbers = serial_numbers  \n",
    "start_date = datetime(2021, 5, 1)\n",
    "end_date = datetime(2022, 8, 31)\n",
    "\n",
    "# Directory for all CSVs\n",
    "base_directory = \"Air_Pollution_Data\"\n",
    "os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "# Data container for all monitors\n",
    "all_data = []\n",
    "\n",
    "# Loop through each serial number and fetch data\n",
    "for serial in serial_numbers:\n",
    "    # Create directory for each monitor\n",
    "    monitor_directory = os.path.join(base_directory, serial)\n",
    "    os.makedirs(monitor_directory, exist_ok=True)\n",
    "    \n",
    "    monitor_data_list = []\n",
    "    \n",
    "    # Generate data for each time period\n",
    "    for start, end in generate_date_ranges(start_date, end_date):\n",
    "        # Set parameters for POST request\n",
    "        params = {\n",
    "            'username': username,\n",
    "            'password': password,\n",
    "            'monitor': serial,\n",
    "            'start': date_to_unix(start.strftime('%Y-%m-%d')),\n",
    "            'end': date_to_unix(end.strftime('%Y-%m-%d'))\n",
    "        }\n",
    "        \n",
    "        # Send the POST request\n",
    "        response = requests.post(url, headers=headers, params=params)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Add serial number to each record\n",
    "            for record in data:\n",
    "                record['serial_number'] = serial\n",
    "                monitor_data_list.append(record)\n",
    "                \n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {serial} from {start} to {end}\")\n",
    "            print(\"Status Code:\", response.status_code)\n",
    "            print(\"Response Body:\", response.text)\n",
    "        \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    monitor_df = pd.DataFrame(monitor_data_list)\n",
    "    \n",
    "    # Save to CSV in its respective directory\n",
    "    csv_path = os.path.join(monitor_directory, f\"{serial}.csv\")\n",
    "    monitor_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Collect data for final aggregation\n",
    "    all_data.append(monitor_df)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV\n",
    "combined_csv_path = os.path.join(base_directory, \"Air_pollution_Sonitus.csv\")\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "print(\"All data has been fetched and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TNO4435', 'TNO4438', 'TNO4488']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial_numbers[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeing what the response looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)  \u001b[38;5;66;03m# See what the data actually looks like\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mtype\u001b[39m(data)  \u001b[38;5;66;03m# Check the data type\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "print(data)  # See what the data actually looks like\n",
    "type(data)  # Check the data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "troubleshooting \n",
    "\n",
    "looks like it works, now i modify serial number list and check that it all makes sense. \n",
    "check that it does not create a df every time i run this code but that it only updates the one i have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data has been fetched and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# this works \n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'https://data.smartdublin.ie/sonitus-api/api/hourly-averages'\n",
    "\n",
    "# Set headers\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Define your credentials\n",
    "username = 'dublincityapi'\n",
    "password = 'Xpa5vAQ9ki'\n",
    "\n",
    "# Convert date string to unix timestamp\n",
    "def date_to_unix(date_str):\n",
    "    return int(datetime.strptime(date_str, '%Y-%m-%d').timestamp())\n",
    "\n",
    "# Generate date ranges for the period, 29 days at a time\n",
    "def generate_date_ranges(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        yield current_date, min(end_date, current_date + timedelta(days=15))\n",
    "        current_date += timedelta(days=30)\n",
    "\n",
    "# Monitor serial numbers and date range\n",
    "serial_numbers = serial_numbers \n",
    "start_date = datetime(2021, 5, 1)\n",
    "end_date = datetime(2022, 8, 31)\n",
    "\n",
    "# Directory for all CSVs\n",
    "base_directory = \"Air_Pollution_Data\"\n",
    "os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "# Data container for all monitors\n",
    "all_data = []\n",
    "\n",
    "# Loop through each serial number and fetch data\n",
    "for serial in serial_numbers:\n",
    "    # Create directory for each monitor\n",
    "    monitor_directory = os.path.join(base_directory, serial)\n",
    "    os.makedirs(monitor_directory, exist_ok=True)\n",
    "    \n",
    "    monitor_data_list = []\n",
    "    \n",
    "    # Generate data for each time period\n",
    "    for start, end in generate_date_ranges(start_date, end_date):\n",
    "        # Set parameters for POST request\n",
    "        params = {\n",
    "            'username': username,\n",
    "            'password': password,\n",
    "            'monitor': serial,\n",
    "            'start': date_to_unix(start.strftime('%Y-%m-%d')),\n",
    "            'end': date_to_unix(end.strftime('%Y-%m-%d'))\n",
    "        }\n",
    "        \n",
    "        # Send the POST request\n",
    "        response = requests.post(url, headers=headers, params=params)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            if response.text:  # Check if there is any text in the response\n",
    "                data = response.json()\n",
    "                \n",
    "                # Add serial number to each record\n",
    "                for record in data:\n",
    "                    record['serial_number'] = serial\n",
    "                    monitor_data_list.append(record)\n",
    "            else:\n",
    "                print(f\"No data returned for {serial} from {start} to {end}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {serial} from {start} to {end}\")\n",
    "            print(\"Status Code:\", response.status_code)\n",
    "            print(\"Response Body:\", response.text)\n",
    "        \n",
    "    # Convert the list of dictionaries to a pandas DataFrame\n",
    "    monitor_df = pd.DataFrame(monitor_data_list)\n",
    "    \n",
    "    # Save to CSV in its respective directory\n",
    "    csv_path = os.path.join(monitor_directory, f\"{serial}.csv\")\n",
    "    monitor_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Collect data for final aggregation\n",
    "    all_data.append(monitor_df)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV\n",
    "combined_csv_path = os.path.join(base_directory, \"Air_pollution_Sonitus.csv\")\n",
    "combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "print(\"All data has been fetched and saved successfully.\")\n",
    "\n",
    "\n",
    "# add lat and long to each sensor \n",
    "# insert every sensor in the serial number for loop thing\n",
    "# check if there is missing information for days or hours \n",
    "# put code stuff in folders so the gh is better \n",
    "# make your code prettier in both cases, hourly weather data and sonitus.api \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Serial Numbers in the Dataset:\n",
      "['TNO4435' 'TNO4438' 'TNO4488']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sonitus_data = pd.read_csv(\"C:/Users/Giulia Maria/Documents/GitHub/ML Proj Dublin/Hyperlocal-Air-Quality-Prediction-in-Dublin/Air_Pollution_Data/Air_pollution_Sonitus.csv\")\n",
    "sonitus_data.head()\n",
    "\n",
    "# # Check the unique entries in the 'serial_number' column\n",
    "unique_serial_numbers = sonitus_data['serial_number'].unique()\n",
    "\n",
    "# # Print the unique serial numbers\n",
    "print(\"Unique Serial Numbers in the Dataset:\")\n",
    "print(unique_serial_numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
