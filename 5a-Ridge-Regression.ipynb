{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting Air Pollution Levels using Linear Models \n",
    "\n",
    "This notebook demonstrates the steps to use Linear, Ridge and a Lasso Regression models to predict air pollution levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hour', 'date', 'NO_ugm3', 'NO2_ugm3', 'O3_ugm3', 'CO_mgm3', 'CO2_mgm3',\n",
       "       'PM25_ugm3', 'SiteID', 'Lat', 'Long', 'day_of_week', 'avgtempC',\n",
       "       'maxtempC', 'mintempC', 'sunHour', 'uvIndex', 'humidity',\n",
       "       'winddirDegree', 'windspeedKmph', 'cloudcover', 'precipMM', 'pressure',\n",
       "       'DCC-AQ1-co', 'DCC-AQ1-no', 'DCC-AQ10-no', 'DCC-AQ13-no', 'DCC-AQ5-no',\n",
       "       'DCC-AQ6-no', 'DCC-AQ1-no2', 'DCC-AQ10-no2', 'DCC-AQ13-no2',\n",
       "       'DCC-AQ22-no2', 'DCC-AQ5-no2', 'DCC-AQ6-no2', 'DCC-AQ69-no2',\n",
       "       'DCC-AQ22-o3', 'DCC-AQ69-o3', 'DCC-AQ10-pm1', 'DCC-AQ13-pm1',\n",
       "       'DCC-AQ2-pm1', 'DCC-AQ3-pm1', 'DCC-AQ4-pm1', 'DCC-AQ5-pm1',\n",
       "       'DCC-AQ52-pm1', 'DCC-AQ6-pm1', 'TNO2161-pm1', 'TNO2162-pm1',\n",
       "       'TNO4435-pm1', 'TNT1088-pm1', 'DCC-AQ10-pm10', 'DCC-AQ13-pm10',\n",
       "       'DCC-AQ2-pm10', 'DCC-AQ22-pm10', 'DCC-AQ3-pm10', 'DCC-AQ4-pm10',\n",
       "       'DCC-AQ5-pm10', 'DCC-AQ52-pm10', 'DCC-AQ6-pm10', 'TNO2161-pm10',\n",
       "       'TNO2162-pm10', 'TNO4435-pm10', 'TNT1088-pm10', 'DCC-AQ10-pm2_5',\n",
       "       'DCC-AQ13-pm2_5', 'DCC-AQ2-pm2_5', 'DCC-AQ22-pm2_5', 'DCC-AQ3-pm2_5',\n",
       "       'DCC-AQ4-pm2_5', 'DCC-AQ5-pm2_5', 'DCC-AQ52-pm2_5', 'DCC-AQ6-pm2_5',\n",
       "       'TNO2161-pm2_5', 'TNO2162-pm2_5', 'TNO4435-pm2_5', 'TNT1088-pm2_5',\n",
       "       'DCC-AQ10-pm4', 'DCC-AQ13-pm4', 'DCC-AQ2-pm4', 'DCC-AQ3-pm4',\n",
       "       'DCC-AQ4-pm4', 'DCC-AQ5-pm4', 'DCC-AQ52-pm4', 'DCC-AQ6-pm4',\n",
       "       'DCC-AQ1-so2', 'DCC-AQ13-so2', 'DCC-AQ22-so2', 'TNO2161-tsp',\n",
       "       'TNO2162-tsp', 'TNO4435-tsp', 'TNT1088-tsp', 'Sum_Volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"prepped_data/Full_data.csv\") \n",
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = full_data[full_data['date'] >= '2022-05-01']\n",
    "df_train = full_data[full_data['date'] < '2022-05-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Split train into X and Y\n",
    "Xtrain = df_train.iloc[:, 8:].values\n",
    "ytrain = df_train[\"PM25_ugm3\"].values\n",
    "\n",
    "# #Split test into X and Y\n",
    "Xtest = df_test.iloc[:, 8:].values\n",
    "ytest = df_test[\"PM25_ugm3\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot one encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Giulia Maria\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming you know the names of the categorical columns\n",
    "categorical_columns = ['SiteID', 'day_of_week']  # List of categorical column names\n",
    "\n",
    "# Convert arrays back to DataFrame for easier manipulation\n",
    "Xtrain_df = pd.DataFrame(Xtrain, columns=df_train.columns[8:])\n",
    "Xtest_df = pd.DataFrame(Xtest, columns=df_test.columns[8:])\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "encoder.fit(Xtrain_df[categorical_columns])\n",
    "\n",
    "# Transform both training and test data\n",
    "Xtrain_encoded = encoder.transform(Xtrain_df[categorical_columns])\n",
    "Xtest_encoded = encoder.transform(Xtest_df[categorical_columns])\n",
    "\n",
    "# Create DataFrames from the encoded arrays, include column names for easier merging\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "Xtrain_encoded_df = pd.DataFrame(Xtrain_encoded, columns=encoded_columns)\n",
    "Xtest_encoded_df = pd.DataFrame(Xtest_encoded, columns=encoded_columns)\n",
    "\n",
    "# Drop the original categorical columns and concat the new encoded columns\n",
    "Xtrain_final = pd.concat([Xtrain_df.drop(categorical_columns, axis=1), Xtrain_encoded_df], axis=1)\n",
    "Xtest_final = pd.concat([Xtest_df.drop(categorical_columns, axis=1), Xtest_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)   \n",
    "# # imputing \n",
    "# imputer = SimpleImputer(strategy=\"mean\")\n",
    "# Xtrain_1 = imputer.fit_transform(Xtrain_final)  # Impute\n",
    "# Xtest_1 = imputer.transform(Xtest_final)  # Impute\n",
    "\n",
    "# # Convert back to DataFrame\n",
    "# Xtrain_1 = pd.DataFrame(Xtrain_1, columns=Xtrain_final.columns)\n",
    "# Xtest_1 = pd.DataFrame(Xtest_1, columns=Xtest_final.columns)\n",
    "\n",
    "# # scaling \n",
    "# scaler = StandardScaler()\n",
    "# Xtrain_1 = scaler.fit_transform(Xtrain_1)  # Scale\n",
    "# Xtest_1 = scaler.transform(Xtest_1)  # Scale\n",
    "\n",
    "# # Convert back to DataFrame\n",
    "# Xtrain_1 = pd.DataFrame(Xtrain_1, columns=Xtrain_final.columns)\n",
    "# Xtest_1 = pd.DataFrame(Xtest_1, columns=Xtest_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)   \n",
    "\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "# Xtrain_KNN = imputer.fit_transform(Xtrain_final)\n",
    "# Xtest_KNN = imputer.transform(Xtest_final)\n",
    "\n",
    "# # Convert back to DataFrame\n",
    "# Xtrain_2 = pd.DataFrame(Xtrain_KNN, columns=Xtrain_final.columns)\n",
    "# Xtest_2 = pd.DataFrame(Xtest_KNN, columns=Xtest_final.columns)\n",
    "\n",
    "# Xtrain = scaler.fit_transform(Xtrain_2)\n",
    "# Xtest = scaler.transform(Xtest_2)\n",
    "\n",
    "# # Convert back to DataFrame\n",
    "# Xtrain_KNN = pd.DataFrame(Xtrain, columns=Xtrain_final.columns)\n",
    "# Xtest_KNN = pd.DataFrame(Xtest, columns=Xtest_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34923,)\n",
      "(8272,)\n"
     ]
    }
   ],
   "source": [
    "# print(Xtrain_KNN.shape) \n",
    "# print(Xtest_KNN.shape)  \n",
    "\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)\n",
    "\n",
    "# print(Xtrain_1.shape)\n",
    "# print(Xtest_1.shape)\n",
    "\n",
    "# print(ytrain.shape)\n",
    "# print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mine\n",
    "\n",
    "Xtrain_KNN_encoded = pd.read_csv(\"prepped_data/Xtrain_KNN_encoded.csv\")\n",
    "Xtest_KNN_encoded = pd.read_csv(\"prepped_data/Xtest_KNN_encoded.csv\")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with KNN imputed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: -9.31181087046276e+24\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "\n",
    "# You can still use TimeSeriesSplit for cross-validation to evaluate model performance\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "scores = cross_val_score(linear_model, Xtrain_KNN_encoded, ytrain, cv=tscv, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the average of the scores (neg_mean_squared_error)\n",
    "print(\"Average MSE:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 35.73540005659166\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "linear_model.fit(Xtrain_KNN_encoded, ytrain)\n",
    "\n",
    "# Predict on the test data\n",
    "ypred_linear = linear_model.predict(Xtest_KNN_encoded)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(ytest, ypred_linear)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ridge Regression\n",
    "ridge = Ridge()\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 4, 100)  # This creates 20 logarithmically spaced values between 10^-4 and 10^4.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters: {'alpha': 8302.175681319752}\n",
      "Best score (negative MSE): -52.22462135905255\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearchCV to find the best model\n",
    "grid_search.fit(Xtrain_KNN_encoded, ytrain)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: alpha = 8302.175681319752\n",
      "Best score (negative MSE): -52.22462135905255\n"
     ]
    }
   ],
   "source": [
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Best parameters: alpha =\", best_alpha)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=8302.175681319752)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=8302.175681319752)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=8302.175681319752)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Ridge Regression model with the best alpha\n",
    "ridge_model = Ridge(alpha= best_alpha)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge_model.fit(Xtrain_KNN_encoded, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27.823239142819737\n"
     ]
    }
   ],
   "source": [
    "ypred_ridge = ridge_model.predict(Xtest_KNN_encoded)  # Predict on the test data\n",
    "mse = mean_squared_error(ytest, ypred_ridge)  # Calculate the mean squared error\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "lasso = Lasso()\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 4, 100)  # Creates 100 logarithmically spaced values between 10^-4 and 10^4.\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, cv=tscv, \n",
    "                           scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters: {'alpha': 0.08111308307896872}\n",
      "Best score (negative MSE): -53.68917929499321\n"
     ]
    }
   ],
   "source": [
    "# Runtime 30 minutes\n",
    "# Fit GridSearchCV to find the best model\n",
    "grid_search.fit(Xtrain_KNN_encoded, ytrain)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: alpha = 0.08111308307896872\n",
      "Best score (negative MSE): -53.68917929499321\n"
     ]
    }
   ],
   "source": [
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Best parameters: alpha =\", best_alpha)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.08111308307896872)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.08111308307896872)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.08111308307896872)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Ridge Regression model with the best alpha\n",
    "lasso_model = Lasso(alpha = best_alpha)\n",
    "\n",
    "# Fit the model on the training data\n",
    "lasso_model.fit(Xtrain_KNN_encoded, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 27.09031238631191\n"
     ]
    }
   ],
   "source": [
    "ypred_lasso = lasso_model.predict(Xtest_KNN_encoded)  # Predict on the test data\n",
    "mse = mean_squared_error(ytest, ypred_lasso)  # Calculate the mean squared error\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.95060329 13.97654323  8.62638454 ...  3.79949431  4.99381117\n",
      "  5.77860121]\n",
      "[ 9.27192981 13.00452593  8.58082855 ...  5.03594065  5.63670285\n",
      "  6.54427142]\n",
      "[ 9.25954061 10.51681352  7.84400238 ...  5.73270154  5.66078255\n",
      "  7.39519242]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ypred_linear)\n",
    "print(ypred_ridge)\n",
    "print(ypred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of Linear Model (using r2_score function): -0.19014792007349413\n",
      "R-squared of Ridge (using r2_score function): 0.07336226422274894\n",
      "R-squared of Lasso (using r2_score function): 0.09777198829027356\n"
     ]
    }
   ],
   "source": [
    "r_squared_linear = r2_score(ytest, ypred_linear)\n",
    "print(\"R-squared of Linear Model (using r2_score function):\", r_squared_linear)\n",
    "\n",
    "r_squared_ridge = r2_score(ytest, ypred_ridge)\n",
    "print(\"R-squared of Ridge (using r2_score function):\", r_squared_ridge)\n",
    "\n",
    "r_squared_lasso = r2_score(ytest, ypred_lasso)\n",
    "print(\"R-squared of Lasso (using r2_score function):\", r_squared_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: SiteID_963.0, Coefficient: 129881424610.02441\n",
      "Feature: SiteID_144.0, Coefficient: 126543674884.56956\n",
      "Feature: SiteID_819.0, Coefficient: 115011470972.7988\n"
     ]
    }
   ],
   "source": [
    "# Get feature names (assuming you have them stored in a list)\n",
    "feature_names = linear_model.feature_names_in_ # Replace with your actual feature names\n",
    "\n",
    "# Pair feature names with coefficients\n",
    "feature_coef_pairs = zip(feature_names, linear_model.coef_)\n",
    "\n",
    "# Sort features by coefficient magnitude\n",
    "sorted_features = sorted(feature_coef_pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 3\n",
    "for feature, coef in sorted_features[:top_n]:\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: SiteID_835.0, Coefficient: 0.8307375072683622\n",
      "Feature: SiteID_830.0, Coefficient: 0.5927670969506216\n",
      "Feature: SiteID_80.0, Coefficient: 0.5147536938056233\n"
     ]
    }
   ],
   "source": [
    "# Get feature names (assuming you have them stored in a list)\n",
    "feature_names = ridge_model.feature_names_in_ # Replace with your actual feature names\n",
    "\n",
    "# Pair feature names with coefficients\n",
    "feature_coef_pairs = zip(feature_names, ridge_model.coef_)\n",
    "\n",
    "# Sort features by coefficient magnitude\n",
    "sorted_features = sorted(feature_coef_pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 3\n",
    "for feature, coef in sorted_features[:top_n]:\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: SiteID_835.0, Coefficient: 0.9776238444346154\n",
      "Feature: DCC-AQ10-pm4, Coefficient: 0.9603606420838743\n",
      "Feature: TNT1088-pm2_5, Coefficient: 0.8811241598391167\n"
     ]
    }
   ],
   "source": [
    "# Get feature names (assuming you have them stored in a list)\n",
    "feature_names = lasso_model.feature_names_in_ # Replace with your actual feature names\n",
    "\n",
    "# Pair feature names with coefficients\n",
    "feature_coef_pairs = zip(feature_names, lasso_model.coef_)\n",
    "\n",
    "# Sort features by coefficient magnitude\n",
    "sorted_features = sorted(feature_coef_pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 3\n",
    "for feature, coef in sorted_features[:top_n]:\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
