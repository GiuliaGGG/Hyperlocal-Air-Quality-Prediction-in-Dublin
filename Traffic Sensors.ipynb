{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Convert 'End_Time' column to datetime\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd_Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd_Time\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Extract date part from 'End_Time'\u001b[39;00m\n\u001b[0;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnd_Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdate()\n",
      "\u001b[1;31mTypeError\u001b[0m: strptime() argument 1 must be str, not Series"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = 'data/Traffic_Measurements'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store the final results\n",
    "daily_volume = []\n",
    "\n",
    "# Iterate over each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert 'End_Time' column to datetime\n",
    "    df['End_Time'] = datetime.strptime(df['End_Time'], \"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    # Extract date part from 'End_Time'\n",
    "    df['Date'] = df['End_Time'].date()\n",
    "    \n",
    "    # Group by 'Site' and 'Date', sum 'Sum_Volume'\n",
    "    daily_sum = df.groupby(['Site', 'Date'])['Sum_Volume'].sum().reset_index()\n",
    "    \n",
    "    # Append daily sum to the final results list\n",
    "    daily_volume.append(daily_sum)\n",
    "\n",
    "# Concatenate all daily sums into one DataFrame\n",
    "final_result = pd.concat(daily_volume, ignore_index=True)\n",
    "\n",
    "# Display the final result\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'dsa2 (Python 3.11.7)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = 'data/Traffic_Measurements'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store the final results\n",
    "daily_volume = []\n",
    "\n",
    "# Iterate over each CSV file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert 'End_Time' column to datetime using the provided method\n",
    "    df['End_Time'] = df['End_Time'].apply(lambda x: datetime.strptime(str(x), \"%Y%m%d%H%M%S\"))\n",
    "    \n",
    "    # Extract date part from 'End_Time'\n",
    "    df['Date'] = df['End_Time'].dt.date\n",
    "    \n",
    "    # Group by 'Site' and 'Date', sum 'Sum_Volume'\n",
    "    daily_sum = df.groupby(['Site', 'Date'])['Sum_Volume'].sum().reset_index()\n",
    "    \n",
    "    # Append daily sum to the final results list\n",
    "    daily_volume.append(daily_sum)\n",
    "\n",
    "# Concatenate all daily sums into one DataFrame\n",
    "final_result = pd.concat(daily_volume, ignore_index=True)\n",
    "\n",
    "# Display the final result\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Site        Date  Sum_Volume               Site_Description_Cap  \\\n",
      "0          1  2022-04-01        5960   ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
      "1          1  2022-04-02        5094   ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
      "2          1  2022-04-03        3938   ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
      "3          1  2022-04-04        5565   ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
      "4          1  2022-04-05        5640   ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
      "...      ...         ...         ...                                ...   \n",
      "223208   974  2022-06-28        5885         BLACKHORSE AVE @ NEPHIN RD   \n",
      "223209   974  2022-06-29        5755         BLACKHORSE AVE @ NEPHIN RD   \n",
      "223210   974  2022-06-30        5893         BLACKHORSE AVE @ NEPHIN RD   \n",
      "223211   514  2021-11-16           0  KIMMAGE RD LWR @ MOUNT ARGUS VIEW   \n",
      "223212   639  2021-11-16           0      TONLEGEE RD @ SPRINGDALE ROAD   \n",
      "\n",
      "                   Site_Description_Lower  Region        Lat      Long  \\\n",
      "0        abbey st @ marlborough st (luas)   CCITY  53.348754 -6.257607   \n",
      "1        abbey st @ marlborough st (luas)   CCITY  53.348754 -6.257607   \n",
      "2        abbey st @ marlborough st (luas)   CCITY  53.348754 -6.257607   \n",
      "3        abbey st @ marlborough st (luas)   CCITY  53.348754 -6.257607   \n",
      "4        abbey st @ marlborough st (luas)   CCITY  53.348754 -6.257607   \n",
      "...                                   ...     ...        ...       ...   \n",
      "223208         blackhorse ave @ nephin rd  WCITY1  53.362728 -6.311709   \n",
      "223209         blackhorse ave @ nephin rd  WCITY1  53.362728 -6.311709   \n",
      "223210         blackhorse ave @ nephin rd  WCITY1  53.362728 -6.311709   \n",
      "223211  kimmage rd lwr @ mount argus view     NaN  53.319874 -6.288050   \n",
      "223212      tonlegee rd @ springdale road     NaN  53.390253 -6.191502   \n",
      "\n",
      "          Site_Type  \n",
      "0        SCATS Site  \n",
      "1        SCATS Site  \n",
      "2        SCATS Site  \n",
      "3        SCATS Site  \n",
      "4        SCATS Site  \n",
      "...             ...  \n",
      "223208   SCATS Site  \n",
      "223209   SCATS Site  \n",
      "223210   SCATS Site  \n",
      "223211   SCATS Site  \n",
      "223212  Signal Site  \n",
      "\n",
      "[223213 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('data/Traffic_combined.csv')\n",
    "df2 = pd.read_csv('data/dcc_traffic_signals_20221130.csv')\n",
    "\n",
    "df2 = df2.rename(columns={'SiteID': 'Site'})\n",
    "\n",
    "merged_traffic = pd.merge(df1, df2, how='inner', on='Site')\n",
    "\n",
    "# common_column should be the column you want to join on from both DataFrames\n",
    "merged_traffic.to_csv('Traffic_merged_combined.csv', index=False)\n",
    "# Display the merged DataFrame\n",
    "print(merged_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223213, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sum_Volume</th>\n",
       "      <th>Site_Description_Cap</th>\n",
       "      <th>Site_Description_Lower</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Site_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>5960</td>\n",
       "      <td>ABBEY ST @ MARLBOROUGH ST (LUAS)</td>\n",
       "      <td>abbey st @ marlborough st (luas)</td>\n",
       "      <td>CCITY</td>\n",
       "      <td>53.348754</td>\n",
       "      <td>-6.257607</td>\n",
       "      <td>SCATS Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>5094</td>\n",
       "      <td>ABBEY ST @ MARLBOROUGH ST (LUAS)</td>\n",
       "      <td>abbey st @ marlborough st (luas)</td>\n",
       "      <td>CCITY</td>\n",
       "      <td>53.348754</td>\n",
       "      <td>-6.257607</td>\n",
       "      <td>SCATS Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>3938</td>\n",
       "      <td>ABBEY ST @ MARLBOROUGH ST (LUAS)</td>\n",
       "      <td>abbey st @ marlborough st (luas)</td>\n",
       "      <td>CCITY</td>\n",
       "      <td>53.348754</td>\n",
       "      <td>-6.257607</td>\n",
       "      <td>SCATS Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>5565</td>\n",
       "      <td>ABBEY ST @ MARLBOROUGH ST (LUAS)</td>\n",
       "      <td>abbey st @ marlborough st (luas)</td>\n",
       "      <td>CCITY</td>\n",
       "      <td>53.348754</td>\n",
       "      <td>-6.257607</td>\n",
       "      <td>SCATS Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>5640</td>\n",
       "      <td>ABBEY ST @ MARLBOROUGH ST (LUAS)</td>\n",
       "      <td>abbey st @ marlborough st (luas)</td>\n",
       "      <td>CCITY</td>\n",
       "      <td>53.348754</td>\n",
       "      <td>-6.257607</td>\n",
       "      <td>SCATS Site</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site        Date  Sum_Volume              Site_Description_Cap  \\\n",
       "0     1  2022-04-01        5960  ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
       "1     1  2022-04-02        5094  ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
       "2     1  2022-04-03        3938  ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
       "3     1  2022-04-04        5565  ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
       "4     1  2022-04-05        5640  ABBEY ST @ MARLBOROUGH ST (LUAS)   \n",
       "\n",
       "             Site_Description_Lower Region        Lat      Long   Site_Type  \n",
       "0  abbey st @ marlborough st (luas)  CCITY  53.348754 -6.257607  SCATS Site  \n",
       "1  abbey st @ marlborough st (luas)  CCITY  53.348754 -6.257607  SCATS Site  \n",
       "2  abbey st @ marlborough st (luas)  CCITY  53.348754 -6.257607  SCATS Site  \n",
       "3  abbey st @ marlborough st (luas)  CCITY  53.348754 -6.257607  SCATS Site  \n",
       "4  abbey st @ marlborough st (luas)  CCITY  53.348754 -6.257607  SCATS Site  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merged_traffic.shape)\n",
    "\n",
    "merged_traffic.isna().sum()\n",
    "\n",
    "merged_traffic.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
